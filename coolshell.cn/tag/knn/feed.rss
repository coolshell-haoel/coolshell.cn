<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>KNN | 酷 壳 - CoolShell</title>
	<atom:link href="https://coolshell.cn/tag/knn/feed" rel="self" type="application/rss+xml" />
	<link>https://coolshell.cn</link>
	<description>享受编程和技术所带来的快乐 - Coding Your Ambition</description>
	<lastBuildDate>Fri, 17 Aug 2012 16:38:57 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.2</generator>
	<item>
		<title>K Nearest Neighbor 算法</title>
		<link>https://coolshell.cn/articles/8052.html</link>
					<comments>https://coolshell.cn/articles/8052.html#comments</comments>
		
		<dc:creator><![CDATA[陈皓]]></dc:creator>
		<pubDate>Fri, 17 Aug 2012 00:15:30 +0000</pubDate>
				<category><![CDATA[杂项资源]]></category>
		<category><![CDATA[程序设计]]></category>
		<category><![CDATA[Algorithm]]></category>
		<category><![CDATA[Data Mining]]></category>
		<category><![CDATA[KNN]]></category>
		<category><![CDATA[Max Heap]]></category>
		<guid isPermaLink="false">http://coolshell.cn/?p=8052</guid>

					<description><![CDATA[<p>K Nearest Neighbor算法又叫KNN算法，这个算法是机器学习里面一个比较经典的算法， 总体来说KNN算法是相对比较容易理解的算法。其中的K表示最接...</p>
<p class="read-more"><a class="btn btn-default" href="https://coolshell.cn/articles/8052.html"> Read More<span class="screen-reader-text">  Read More</span></a></p>
The post <a href="https://coolshell.cn/articles/8052.html">K Nearest Neighbor 算法</a> first appeared on <a href="https://coolshell.cn">酷 壳 - CoolShell</a>.]]></description>
										<content:encoded><![CDATA[<p><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3415450859608158"
     crossorigin="anonymous"></script>K Nearest Neighbor算法又叫KNN算法，这个算法是机器学习里面一个比较经典的算法， 总体来说KNN算法是相对比较容易理解的算法。其中的K表示最接近自己的K个数据样本。KNN算法和<a title="K-Means 算法" href="https://coolshell.cn/articles/7779.html" target="_blank">K-Means算法</a>不同的是，K-Means算法用来聚类，用来判断哪些东西是一个比较相近的类型，而KNN算法是用来做归类的，也就是说，有一个样本空间里的样本分成很几个类型，然后，给定一个待分类的数据，通过计算接近自己最近的K个样本来判断这个待分类数据属于哪个分类。<strong>你可以简单的理解为由那离自己最近的K个点来投票决定待分类数据归为哪一类</strong>。</p>
<p style="text-align: left;">Wikipedia上的<a href="http://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm" target="_blank">KNN词条</a>中有一个比较经典的图如下：</p>
<p style="text-align: center;"><img decoding="async" loading="lazy" class="size-full wp-image-8053 aligncenter" title="KNN Classification" src="https://coolshell.cn/wp-content/uploads/2012/08/220px-KnnClassification.svg_.png" alt="" width="220" height="199" /></p>
<p style="text-align: left;">从上图中我们可以看到，图中的有两个类型的样本数据，一类是蓝色的正方形，另一类是红色的三角形。而那个绿色的圆形是我们待分类的数据。</p>
<ul>
<li>如果K=3，那么离绿色点最近的有2个红色三角形和1个蓝色的正方形，这3个点投票，于是绿色的这个待分类点属于红色的三角形。</li>
</ul>
<ul>
<li>如果K=5，那么离绿色点最近的有2个红色三角形和3个蓝色的正方形，这5个点投票，于是绿色的这个待分类点属于蓝色的正方形。</li>
</ul>
<p>我们可以看到，机器学习的本质——<strong>是基于一种数据统计的方法</strong>！那么，这个算法有什么用呢？我们来看几个示例。</p>
<p><span id="more-8052"></span></p>
<h4>产品质量判断</h4>
<p>假设我们需要判断纸巾的品质好坏，纸巾的品质好坏可以抽像出两个向量，一个是“酸腐蚀的时间”，一个是“能承受的压强”。如果我们的样本空间如下：（所谓样本空间，又叫Training Data，也就是用于机器学习的数据）</p>
<table style="margin: auto;" border="1" cellspacing="3" cellpadding="3">
<tbody>
<tr>
<td valign="top" width="33%">
<p align="center"><strong>向量X1</strong></p>
<p align="center"><strong>耐酸时间（秒）</strong></p>
</td>
<td valign="top" width="33%">
<p align="center"><strong>向量X2</strong></p>
<p align="center"><strong>圧强(公斤/平方米)</strong></p>
</td>
<td valign="top" width="33%">
<p align="center"><strong>品质Y</strong></p>
</td>
</tr>
<tr>
<td valign="top" width="33%">
<p align="center">7</p>
</td>
<td valign="top" width="33%">
<p align="center">7</p>
</td>
<td valign="top" width="33%">
<p align="center">坏</p>
</td>
</tr>
<tr>
<td valign="top" width="33%">
<p align="center">7</p>
</td>
<td valign="top" width="33%">
<p align="center">4</p>
</td>
<td valign="top" width="33%">
<p align="center">坏</p>
</td>
</tr>
<tr>
<td valign="top" width="33%">
<p align="center">3</p>
</td>
<td valign="top" width="33%">
<p align="center">4</p>
</td>
<td valign="top" width="33%">
<p align="center">好</p>
</td>
</tr>
<tr>
<td valign="top" width="33%">
<p align="center">1</p>
</td>
<td valign="top" width="33%">
<p align="center">4</p>
</td>
<td valign="top" width="33%">
<p align="center">好</p>
</td>
</tr>
</tbody>
</table>
<p>那么，如果 X1 = 3 和 X2 = 7， 这个毛巾的品质是什么呢？这里就可以用到KNN算法来判断了。</p>
<p>假设K=3，K应该是一个奇数，这样可以保证不会有平票，下面是我们计算（3，7）到所有点的距离。（关于那些距离公式，可以参看<a title="K-Means 算法" href="https://coolshell.cn/articles/7779.html" target="_blank">K-Means算法中的距离公式</a>）</p>
<table style="margin: auto;" border="1" cellspacing="3" cellpadding="3">
<tbody>
<tr>
<td valign="top" width="25%">
<p align="center"><strong>向量X1</strong></p>
<p align="center"><strong>耐酸时间（秒）</strong></p>
</td>
<td valign="top" width="25%">
<p align="center"><strong>向量X2</strong></p>
<p align="center"><strong>圧强(公斤/平方米)</strong></p>
</td>
<td valign="top" width="25%">
<p align="center"><strong>计算到 (3, 7)的距离</strong></p>
</td>
<td valign="top" width="25%">
<p align="center"><strong>向量Y</strong></p>
</td>
</tr>
<tr>
<td valign="top" width="25%">
<p align="center">7</p>
</td>
<td valign="top" width="25%">
<p align="center">7</p>
</td>
<td valign="top" width="25%">
<p align="center"><strong><img decoding="async" loading="lazy" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_Numerical-example_clip_image004.gif" alt="" width="144" height="24" /></strong></p>
</td>
<td style="text-align: center;" valign="top" width="25%"> 坏</td>
</tr>
<tr>
<td valign="top" width="25%">
<p align="center">7</p>
</td>
<td valign="top" width="25%">
<p align="center">4</p>
</td>
<td valign="top" width="25%">
<p align="center"><strong><img decoding="async" loading="lazy" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_Numerical-example_clip_image006.gif" alt="" width="145" height="24" /></strong></p>
</td>
<td style="text-align: center;" valign="top" width="25%"> N/A</td>
</tr>
<tr>
<td valign="top" width="25%">
<p align="center">3</p>
</td>
<td valign="top" width="25%">
<p align="center">4</p>
</td>
<td valign="top" width="25%">
<p align="center"><strong><img decoding="async" loading="lazy" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_Numerical-example_clip_image008.gif" alt="" width="136" height="24" /></strong></p>
</td>
<td style="text-align: center;" valign="top" width="25%"> 好</td>
</tr>
<tr>
<td valign="top" width="25%">
<p align="center">1</p>
</td>
<td valign="top" width="25%">
<p align="center">4</p>
</td>
<td valign="top" width="25%">
<p align="center"><strong><img decoding="async" loading="lazy" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_Numerical-example_clip_image010.gif" alt="" width="140" height="24" /></strong></p>
</td>
<td style="text-align: center;" valign="top" width="25%"> 好</td>
</tr>
</tbody>
</table>
<p>所以，最后的投票，好的有2票，坏的有1票，最终需要测试的（3，7）是合格品。（当然，你还可以使用权重——可以把距离值做为权重，越近的权重越大，这样可能会更准确一些）</p>
<p><strong>注：<a href="http://people.revoledu.com/kardi/tutorial/KNN/KNN_Numerical-example.html" target="_blank">示例来自这里</a>，<a href="https://coolshell.cn/wp-content/uploads/2012/08/K-NearestNeighbors.xls">K-NearestNeighbors Excel表格下载</a></strong></p>
<h4>预测</h4>
<p>假设我们有下面一组数据，假设X是流逝的秒数，Y值是随时间变换的一个数值（你可以想像是股票值）</p>
<p><img decoding="async" loading="lazy" class="aligncenter" title="KNN_TimeSeries_clip_image004" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image004.jpg" alt="" width="191" height="187" /></p>
<p>那么，当时间是6.5秒的时候，Y值会是多少呢？我们可以用KNN算法来预测之。</p>
<p>这里，让我们假设K=2，于是我们可以计算所有X点到6.5的距离，如：X=5.1，距离是 | 6.5 – 5.1 | = 1.4， X = 1.2 那么距离是 | 6.5 – 1.2 | = 5.3 。于是我们得到下面的表：</p>
<p><img decoding="async" loading="lazy" class="aligncenter" title="KNN_TimeSeries_clip_image006" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image006.jpg" alt="" width="312" height="120" /></p>
<p>注意，上图中因为K=2，所以得到X=4 和 X =5.1的点最近，得到的Y的值分别为27和8，在这种情况下，我们可以简单的使用平均值来计算：<img decoding="async" loading="lazy" title="KNN_TimeSeries_clip_image008" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image008.gif" alt="" width="87" height="41" /></p>
<p>于是，最终预测的数值为：17.5</p>
<p><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8072" title="KNN_TimeSeries_clip_image010" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image010.jpg" alt="" width="402" height="305" srcset="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image010.jpg 402w, https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image010-300x227.jpg 300w" sizes="(max-width: 402px) 100vw, 402px" /></p>
<p><strong>注：<a href="http://people.revoledu.com/kardi/tutorial/KNN/KNN_TimeSeries.htm" target="_blank">示例来自这里</a>，<a href="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries.xls">KNN_TimeSeries Excel表格下载</a></strong></p>
<h4>插值，平滑曲线</h4>
<p>KNN算法还可以用来做平滑曲线用，这个用法比较另类。假如我们的样本数据如下（和上面的一样）：</p>
<p><img decoding="async" loading="lazy" class="aligncenter" title="KNN_TimeSeries_clip_image012" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image012.jpg" alt="" width="335" height="35" /></p>
<p>要平滑这些点，我们需要在其中插入一些值，比如我们用步长为0.1开始插值，从0到6开始，计算到所有X点的距离（绝对值），下图给出了从0到0.5 的数据：</p>
<p><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8074" title="KNN_TimeSeries_clip_image014" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image014.jpg" alt="" width="334" height="152" srcset="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image014.jpg 334w, https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image014-300x136.jpg 300w" sizes="(max-width: 334px) 100vw, 334px" /></p>
<p>下图给出了从2.5到3.5插入的11个值，然后计算他们到各个X的距离，假值K=4，那么我们就用最近4个X的Y值，然后求平均值，得到下面的表：</p>
<p><img decoding="async" loading="lazy" class="aligncenter" title="KNN_TimeSeries_clip_image016" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image016.jpg" alt="" width="576" height="206" /></p>
<p>于是可以从0.0, 0.1, 0.2, 0.3 &#8230;. 1.1, 1.2, 1.3&#8230;..3.1, 3.2&#8230;..5.8, 5.9, 6.0 一个大表，跟据K的取值不同，得到下面的图：</p>
<table style="border: 0px; margin: auto;">
<tbody>
<tr>
<td><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8080" title="KNN_TimeSeries_clip_image026" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image026.jpg" alt="" width="262" height="246" /></td>
<td><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8079" title="KNN_TimeSeries_clip_image024" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image024.jpg" alt="" width="270" height="249" /></td>
</tr>
<tr>
<td><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8078" title="KNN_TimeSeries_clip_image022" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image022.jpg" alt="" width="262" height="244" /></td>
<td><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8077" title="KNN_TimeSeries_clip_image020" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image020.jpg" alt="" width="251" height="234" /></td>
</tr>
<tr>
<td><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8076" title="KNN_TimeSeries_clip_image018" src="https://coolshell.cn/wp-content/uploads/2012/08/KNN_TimeSeries_clip_image018.jpg" alt="" width="246" height="228" /></td>
</tr>
</tbody>
</table>
<p><strong>注：<a href="http://people.revoledu.com/kardi/tutorial/KNN/KNN_TimeSeries.htm" target="_blank">示例来自这里</a>，<a href="https://coolshell.cn/wp-content/uploads/2012/08/KNN_Smoothing.xls">KNN_Smoothing Excel表格下载</a></strong></p>
<h4>后记</h4>
<p>最后，我想再多说两个事，</p>
<p>1） 一个是机器学习，算法基本上都比较简单，最难的是数学建模，把那些业务中的特性抽象成向量的过程，另一个是选取适合模型的数据样本。这两个事都不是简单的事。算法反而是比较简单的事。</p>
<p>2）对于KNN算法中找到离自己最近的K个点，是一个很经典的算法面试题，需要使用到的数据结构是“<a href="http://en.wikipedia.org/wiki/Binary_heap" target="_blank">最大堆——Max Heap</a>”，一种二叉树。你可以看看相关的算法。</p>
<p>（全文完）<!--



<p align="center"><a href= target=_blank><img decoding="async" src=""></a></p>





<p align="center"><img decoding="async" src="https://coolshell.cn/wp-content/uploads/2020/03/coolshell.weixin.jpg"> <img decoding="async" loading="lazy" src="https://coolshell.cn/wp-content/uploads/2020/03/coolshell.mini_.jpg" width="300" height="300"> <br />关注CoolShell微信公众账号和微信小程序</p>

 

--></p>
<div style="margin-top: 15px; font-size: 16px;color: #cc0000;">
<p align="center"><strong>（转载本站文章请注明作者和出处 <a href="https://coolshell.cn/">酷 壳 &#8211; CoolShell</a> ，请勿用于任何商业用途）</strong></p>
</div>

<div class="wp_rp_wrap  wp_rp_vertical_m" id="wp_rp_first"><div class="wp_rp_content"><h3 class="related_post_title">相关文章</h3><ul class="related_post wp_rp"><li ><a href="https://coolshell.cn/articles/7779.html" class="wp_rp_thumbnail"><img src="https://coolshell.cn/wp-content/uploads/2012/06/K-Means-150x150.gif" alt="K-Means 算法" width="150" height="150" /></a><a href="https://coolshell.cn/articles/7779.html" class="wp_rp_title">K-Means 算法</a></li><li ><a href="https://coolshell.cn/articles/17225.html" class="wp_rp_thumbnail"><img src="https://coolshell.cn/wp-content/uploads/2015/08/cuckoo-150x150.jpg" alt="Cuckoo Filter：设计与实现" width="150" height="150" /></a><a href="https://coolshell.cn/articles/17225.html" class="wp_rp_title">Cuckoo Filter：设计与实现</a></li><li ><a href="https://coolshell.cn/articles/12052.html" class="wp_rp_thumbnail"><img src="https://coolshell.cn/wp-content/plugins/wordpress-23-related-posts-plugin/static/thumbs/29.jpg" alt="Leetcode 编程训练" width="150" height="150" /></a><a href="https://coolshell.cn/articles/12052.html" class="wp_rp_title">Leetcode 编程训练</a></li><li ><a href="https://coolshell.cn/articles/11847.html" class="wp_rp_thumbnail"><img src="https://coolshell.cn/wp-content/uploads/2014/08/puzzle-150x150.png" alt="谜题的答案和活动的心得体会" width="150" height="150" /></a><a href="https://coolshell.cn/articles/11847.html" class="wp_rp_title">谜题的答案和活动的心得体会</a></li><li ><a href="https://coolshell.cn/articles/11832.html" class="wp_rp_thumbnail"><img src="https://coolshell.cn/wp-content/uploads/2014/08/538efefbgw1eiz9cvx78fj20rm0fmdi8-150x150.jpg" alt="【活动】解迷题送礼物" width="150" height="150" /></a><a href="https://coolshell.cn/articles/11832.html" class="wp_rp_title">【活动】解迷题送礼物</a></li><li ><a href="https://coolshell.cn/articles/10590.html" class="wp_rp_thumbnail"><img src="https://coolshell.cn/wp-content/uploads/2013/10/QR-Code-Overview-150x150.jpeg" alt="二维码的生成细节和原理" width="150" height="150" /></a><a href="https://coolshell.cn/articles/10590.html" class="wp_rp_title">二维码的生成细节和原理</a></li></ul></div></div>The post <a href="https://coolshell.cn/articles/8052.html">K Nearest Neighbor 算法</a> first appeared on <a href="https://coolshell.cn">酷 壳 - CoolShell</a>.]]></content:encoded>
					
					<wfw:commentRss>https://coolshell.cn/articles/8052.html/feed</wfw:commentRss>
			<slash:comments>51</slash:comments>
		
		
			</item>
	</channel>
</rss>
